{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206c73fb-db8b-44f0-b938-f9bfa1e5970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from utils import *\n",
    "from get_data import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# from manifold_torch import Manifold_Tabular_Sampler\n",
    "\n",
    "def arg_parse():\n",
    "    parser = argparse.ArgumentParser(description=\"UMAP discriminator\")\n",
    "    parser.add_argument(\n",
    "            \"--exp\", dest=\"exp\", help=\"Experiments\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "            \"--std\", dest=\"std\", type=float, help=\"Perturbation std\"\n",
    "        )\n",
    "    parser.add_argument(\n",
    "        \"--multiplier\", dest=\"multiplier\", type=int, help=\"Number of times an image is perturbed\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--perturbations\", dest=\"num_perturbations\", type=int, help=\"Number of perturbations\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dim\", dest=\"dim\", type=int, help=\"Number of low dim\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pivots\", dest=\"pivots\", type=int, help=\"Number of pivots\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shuffle\", dest=\"shuffle\", type=bool, help=\"Shuffle the pivots\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "            \"--train_ratio\", dest=\"train_ratio\", type=float, help=\"ratio of training for the rf\"\n",
    "        )\n",
    "    \n",
    "        \n",
    "    parser.set_defaults(\n",
    "        exp = 'compass',\n",
    "        std = 0.0001,\n",
    "        num_perturbations = 100,\n",
    "        multiplier = 100,\n",
    "        dim = 2,\n",
    "        pivots = 20,\n",
    "        shuffle = True,\n",
    "        train_ratio = 0.9\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "# prog_args = arg_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0d8232-adf0-4af4-b610-a44b921b0502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT:  cc\n",
      "MULTIPLIER:  100\n",
      "PERTURBATION_STD:  0.0001\n",
      "DIM:  2\n",
      "PIVOTS:  20\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT = 'cc'\n",
    "PERTURBATION_STD = 0.0001\n",
    "NUM_PERTURBATIONS = 100\n",
    "MULTIPLIER = 100\n",
    "DIM = 2\n",
    "PIVOTS = 20\n",
    "# TRAIN_RATIO = 0.9\n",
    "\n",
    "print(\"EXPERIMENT: \", EXPERIMENT)\n",
    "print(\"MULTIPLIER: \", MULTIPLIER)\n",
    "print(\"PERTURBATION_STD: \", PERTURBATION_STD)\n",
    "print(\"DIM: \", DIM)\n",
    "print(\"PIVOTS: \", PIVOTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86971cc0-ced7-4340-b61a-02e458c96194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data set and do some preprocessing\n",
    "params = Params(\"data/experiment_params.json\")\n",
    "np.random.seed(params.seed)\n",
    "if EXPERIMENT == 'compass':\n",
    "    X, y, cols = get_and_preprocess_compas_data(params)\n",
    "elif EXPERIMENT == 'german':\n",
    "    X, y, cols = get_and_preprocess_german(params)\n",
    "elif EXPERIMENT == 'cc':\n",
    "    X, y, cols = get_and_preprocess_cc(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6b80ac-dbbe-4c0c-8d5c-d64f41d61c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62416f3c-dc42-493f-b73e-eaf81799f9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2e4c72-a5ad-4602-9e0a-0a0167a8ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1994, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape: \", X.shape)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y,test_size = 0.1)\n",
    "ss = StandardScaler().fit(X)\n",
    "xtrain = ss.transform(xtrain)\n",
    "xtest = ss.transform(xtest)\n",
    "xall = ss.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea16c0c1-4bb2-444c-8aac-2144f57de82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(X,y,n_estimators = 100):\n",
    "    the_rf = RandomForestClassifier(n_estimators=n_estimators).fit(X, y)\n",
    "    y_pred = the_rf.predict(X)\n",
    "    the_rf_result = (y_pred == y).sum()\n",
    "    return the_rf, the_rf_result/y.shape[0]\n",
    "\n",
    "def get_discriminator_performance(X,y,rf):\n",
    "    y_pred = rf.predict(X)\n",
    "    the_rf_result = (y_pred == y).sum()\n",
    "    return the_rf_result/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4809a78-dc70-4372-9705-6751d54c0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "def normalize(v, r):\n",
    "    return v/np.sqrt(np.sum(v**2))*r\n",
    "\n",
    "# class Manifold_Tabular_Sampler(object):\n",
    "#     # Expect torch data\n",
    "#     def __init__(self, data, dim = 2, random_state = 1,\n",
    "#                 labels = None,\n",
    "#                 std_train = 0.2):\n",
    "#         \"\"\"Init function.\n",
    "\n",
    "#         Args:\n",
    "#             data: traning data\n",
    "#         \"\"\"\n",
    "#         self.data = data\n",
    "#         self.dim = dim\n",
    "#         self.std_train = std_train\n",
    "#         self.no_training, self.num_features = self.data.shape\n",
    "#         self.data_min = torch.min(self.data)\n",
    "#         self.data_max = torch.max(self.data)\n",
    "#         self.mapper = umap.UMAP(n_components = self.dim, random_state = random_state)\n",
    "#         self.mapper.fit(data)\n",
    "#         self.labels = labels\n",
    "#         self.pivots = None\n",
    "#         self.planes = None\n",
    "        \n",
    "#     def get_pivots(self, labels, no_pivots_per_label = 1, shuffle = False, target_labels = None):        \n",
    "#         if target_labels == None:\n",
    "#             target_labels = torch.unique(labels)\n",
    "        \n",
    "#         buff = []\n",
    "#         for l in target_labels:\n",
    "#             all_idx = (labels == l).nonzero(as_tuple=False)\n",
    "\n",
    "#             if shuffle == False:\n",
    "#                 idx = all_idx[range(no_pivots_per_label)]\n",
    "#             else:\n",
    "#                 idx = all_idx[random.sample(range(len(all_idx)),no_pivots_per_label )]\n",
    "            \n",
    "#             for i in idx:\n",
    "#                 buff.append(i)\n",
    "#         buff = [buff[i].cpu().detach().numpy()[0] for i in range(len(buff))]\n",
    "            \n",
    "#         self.pivots = self.data[buff].clone()\n",
    "#         return buff\n",
    "    \n",
    "#     def transform(self, x_data):\n",
    "#         return self.mapper.transform(x_data)\n",
    "\n",
    "#     def inv_transform(self, low_data):\n",
    "# #         Expect [N,d] data\n",
    "#         return self.mapper.inverse_transform(low_data)\n",
    "\n",
    "    \n",
    "#     def get_G_from_samples(self, x_sample):\n",
    "# #         x_sample should be inside the input distribution\n",
    "#         matA = self.mapper.transform(x_sample.cpu().detach().numpy())\n",
    "#         matB = x_sample.cpu().detach().numpy()\n",
    "#         Xt = np.transpose(matA)\n",
    "#         XtX = np.dot(Xt,matA)\n",
    "#         Xty = np.dot(Xt,matB)\n",
    "#         matG = np.linalg.solve(XtX,Xty)\n",
    "#         return matG\n",
    "    \n",
    "#     def get_G_from_pivots(self):\n",
    "#         matA = self.mapper.transform(self.pivots.cpu().detach().numpy())\n",
    "#         matB = self.pivots.cpu().detach().numpy()\n",
    "#         Xt = np.transpose(matA)\n",
    "#         XtX = np.dot(Xt,matA)\n",
    "#         Xty = np.dot(Xt,matB)\n",
    "#         matG = np.linalg.solve(XtX,Xty)\n",
    "#         return matG\n",
    "    \n",
    "#     def gen_perturbation_base(self, X, perturbation_multiplier=10, perturbation_std = 0.001):\n",
    "# #         Gauss perturbations\n",
    "#         all_x, all_y = [], []\n",
    "#         var = 0\n",
    "#         for _ in range(perturbation_multiplier):\n",
    "#             perturbed_xtrain = np.random.normal(0, perturbation_std, size=X.shape)\n",
    "#             p_train_x = np.vstack((X, np.clip(X + perturbed_xtrain, self.data_min, self.data_max)))\n",
    "#             p_train_y = np.concatenate((np.zeros(X.shape[0]), np.ones(X.shape[0])))\n",
    "#             all_x.append(p_train_x)\n",
    "#             all_y.append(p_train_y)\n",
    "#         all_x = np.vstack(all_x)\n",
    "#         all_y = np.concatenate(all_y)\n",
    "#         return torch.tensor(all_x), torch.tensor(all_y)\n",
    "\n",
    "        \n",
    "#     def get_G_local(self, x, \n",
    "#                     number_of_local_perturbations = 100,\n",
    "#                     local_std = 0.001,\n",
    "#                     perturb_only = True):\n",
    "#         x_sample, y_sample = self.gen_perturbation_base(x.unsqueeze(0),\n",
    "#                                             perturbation_multiplier=number_of_local_perturbations,\n",
    "#                                             perturbation_std = local_std)\n",
    "#         x_reverse = torch.tensor(self.inv_transform(self.transform(x_sample)))\n",
    "#         if perturb_only == True:\n",
    "#             return self.get_G_from_samples(x_reverse[y_sample == 1])\n",
    "#         else:\n",
    "#             return self.get_G_from_samples(x_reverse)\n",
    "    \n",
    "#     def train_pivots(self,  \n",
    "#                      number_of_pivots_per_label = 10,\n",
    "#                      number_of_local_perturbations = 50,\n",
    "#                      local_std = 0.001, \n",
    "#                      shuffle = False):\n",
    "#         if self.pivots == None:\n",
    "#             _ =  self.get_pivots(self.labels, number_of_pivots_per_label, shuffle = shuffle)\n",
    "        \n",
    "#         Gs = []\n",
    "#         Gvs = []\n",
    "#         for pivot in self.pivots:\n",
    "#             G = self.get_G_local(pivot, \n",
    "#                                  number_of_local_perturbations = number_of_local_perturbations,\n",
    "#                                  local_std = local_std)\n",
    "#             Gu, Gd, Gv = np.linalg.svd(G, full_matrices=False)\n",
    "#             Gs.append(G)\n",
    "#             Gvs.append(Gv)\n",
    "        \n",
    "#         self.G_pivots = Gs\n",
    "#         self.Gv_pivots = Gvs\n",
    "        \n",
    "#     def get_pivot_perturbations(self, radius, \n",
    "#                                  number_of_perturbations_per_pivot = 1,\n",
    "#                                  test = False):\n",
    "#         gauss_perturbs = []\n",
    "#         ortho_perturbs = []\n",
    "#         plane_perturbs = []\n",
    "        \n",
    "#         for pivot in range(self.pivots.shape[0]):\n",
    "#             Gv = self.Gv_pivots[pivot]\n",
    "# #             Gv = self.Gv\n",
    "            \n",
    "#             for _ in range(number_of_perturbations_per_pivot):    \n",
    "#                 gauss_noise = np.random.normal(0, 1, size=self.pivots[pivot].shape)\n",
    "#                 plane_noise = np.zeros_like(gauss_noise)\n",
    "#                 for d in range(Gv.shape[0]):\n",
    "#                     proj = np.dot(gauss_noise, Gv[d])\n",
    "#                     plane_noise = plane_noise + proj*Gv[d]        \n",
    "#                 ortho_noise = gauss_noise - plane_noise\n",
    "\n",
    "#                 # noise\n",
    "#                 r = np.random.uniform()*radius\n",
    "#                 ortho_norm = normalize(ortho_noise, r)\n",
    "#                 plane_norm = normalize(plane_noise, r)\n",
    "#                 gauss_norm = normalize(gauss_noise, r)\n",
    "\n",
    "#                 # point clouds\n",
    "#                 ortho_pc = self.pivots[pivot] + ortho_norm\n",
    "#                 plane_pc = self.pivots[pivot] + plane_norm\n",
    "#                 gauss_pc = self.pivots[pivot] + gauss_norm\n",
    "\n",
    "#                 ortho_perturbs.append(ortho_pc)\n",
    "#                 if test == True:\n",
    "#                     plane_perturbs.append(plane_pc)\n",
    "#                     gauss_perturbs.append(gauss_pc)\n",
    "        \n",
    "#         self.ortho_perturbs = torch.stack(ortho_perturbs)\n",
    "#         if test == True:\n",
    "#             self.gauss_perturbs = torch.stack(gauss_perturbs)\n",
    "#             self.plane_perturbs = torch.stack(plane_perturbs)\n",
    "#         else:\n",
    "#             self.gauss_perturbs = None\n",
    "#             self.plane_perturbs = None\n",
    "#         return ortho_perturbs   \n",
    "\n",
    "class Manifold_Tabular_Sampler(object):\n",
    "    # Expect torch data\n",
    "    def __init__(self, data, dim = 2, random_state = 1,\n",
    "                labels = None,\n",
    "                std_train = 0.2):\n",
    "        \"\"\"Init function.\n",
    "\n",
    "        Args:\n",
    "            data: traning data\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.dim = dim\n",
    "        self.std_train = std_train\n",
    "        self.no_training, self.num_features = self.data.shape\n",
    "        self.data_min = torch.min(self.data)\n",
    "        self.data_max = torch.max(self.data)\n",
    "        self.mapper = umap.UMAP(n_components = self.dim, random_state = random_state)\n",
    "        self.mapper.fit(data)\n",
    "        self.labels = labels\n",
    "        self.pivots = None\n",
    "        self.planes = None\n",
    "        \n",
    "    def get_pivots(self, labels, no_pivots_per_label = 1, shuffle = False, target_labels = None):        \n",
    "        if target_labels == None:\n",
    "            target_labels = torch.unique(labels)\n",
    "        \n",
    "        buff = []\n",
    "        for l in target_labels:\n",
    "            all_idx = (labels == l).nonzero(as_tuple=False)\n",
    "\n",
    "            if shuffle == False:\n",
    "                idx = all_idx[range(no_pivots_per_label)]\n",
    "            else:\n",
    "                idx = all_idx[random.sample(range(len(all_idx)),no_pivots_per_label )]\n",
    "            \n",
    "            for i in idx:\n",
    "                buff.append(i)\n",
    "        buff = [buff[i].cpu().detach().numpy()[0] for i in range(len(buff))]\n",
    "            \n",
    "        self.pivots = self.data[buff].clone()\n",
    "        return buff\n",
    "    \n",
    "    def transform(self, x_data):\n",
    "        return self.mapper.transform(x_data)\n",
    "\n",
    "    def inv_transform(self, low_data):\n",
    "#         Expect [N,d] data\n",
    "        return self.mapper.inverse_transform(low_data)\n",
    "\n",
    "    \n",
    "    def get_G_from_samples(self, x_sample):\n",
    "        matA = self.mapper.transform(x_sample.cpu().detach().numpy())\n",
    "        matB = x_sample.cpu().detach().numpy()\n",
    "        Xt = np.transpose(matA)\n",
    "        XtX = np.dot(Xt,matA)\n",
    "        Xty = np.dot(Xt,matB)\n",
    "        matG = np.linalg.solve(XtX,Xty)\n",
    "        return matG\n",
    "    \n",
    "    def get_G_from_pivots(self):\n",
    "        matA = self.mapper.transform(self.pivots.cpu().detach().numpy())\n",
    "        matB = self.pivots.cpu().detach().numpy()\n",
    "        Xt = np.transpose(matA)\n",
    "        XtX = np.dot(Xt,matA)\n",
    "        Xty = np.dot(Xt,matB)\n",
    "        matG = np.linalg.solve(XtX,Xty)\n",
    "        return matG\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0922f85a-44c4-4494-86fa-0809cc09d54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize duration:  11.615175485610962\n"
     ]
    }
   ],
   "source": [
    "TARGET = 0\n",
    "SHUFFLE = False\n",
    "\n",
    "start_time = time.time()\n",
    "manifold_sampler = Manifold_Tabular_Sampler(torch.tensor(xall), dim = DIM, labels = torch.tensor(y))\n",
    "duration = time.time() - start_time\n",
    "print(\"Initialize duration: \", duration)\n",
    "\n",
    "if TARGET == None:\n",
    "    targets = torch.unique(torch.tensor(y))\n",
    "    target_str = 'all'\n",
    "else:\n",
    "    targets = [TARGET]\n",
    "    target_str = str(TARGET)\n",
    "\n",
    "_ = manifold_sampler.get_pivots(manifold_sampler.labels, MULTIPLIER, shuffle = SHUFFLE, target_labels=targets)\n",
    "manifold_G = manifold_sampler.get_G_from_pivots()\n",
    "Gu, Gd, Gv = np.linalg.svd(manifold_G, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb493952-387e-4577-a884-d6380eae9a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RADIUS = 0.005\n",
    "base_RADIUS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3a73c1-26a1-4df6-ac94-58a7157a1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "base_gauss_ = np.random.normal(0, 1, size=manifold_sampler.pivots.shape)\n",
    "r = np.random.uniform()*base_RADIUS\n",
    "base_gauss_norm = normalize(base_gauss_, r)\n",
    "base_pc = manifold_sampler.pivots + base_gauss_norm\n",
    "\n",
    "gauss_noise = np.random.normal(0, 1, size=manifold_sampler.pivots.shape)\n",
    "plane_noise = np.zeros_like(gauss_noise)\n",
    "for d in range(Gv.shape[0]):\n",
    "    proj = np.dot(gauss_noise, Gv[d])\n",
    "    for s in range(plane_noise.shape[0]):\n",
    "        plane_noise[s] = plane_noise[s] + proj[s]*Gv[d]        \n",
    "ortho_noise = gauss_noise - plane_noise\n",
    "\n",
    "# noise\n",
    "r = np.random.uniform()*RADIUS\n",
    "ortho_norm = normalize(ortho_noise, r)\n",
    "plane_norm = normalize(plane_noise, r)\n",
    "gauss_norm = normalize(gauss_noise, r)\n",
    "\n",
    "# point clouds\n",
    "ortho_pc = base_pc + ortho_norm\n",
    "plane_pc = base_pc + plane_norm\n",
    "gauss_pc = base_pc + gauss_norm\n",
    "# ortho_pc = manifold_sampler.to_1d(manifold_sampler.pivots) + ortho_norm\n",
    "# plane_pc = manifold_sampler.to_1d(manifold_sampler.pivots) + plane_norm\n",
    "# gauss_pc = manifold_sampler.to_1d(manifold_sampler.pivots) + gauss_norm\n",
    "\n",
    "ori_pc = manifold_sampler.pivots.cpu().detach().numpy()\n",
    "base_pc = base_pc.cpu().detach().numpy()\n",
    "ortho_pc = ortho_pc.cpu().detach().numpy()\n",
    "plane_pc = plane_pc.cpu().detach().numpy()\n",
    "gauss_pc = gauss_pc.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9e7d2e-e809-4406-95ec-0c1c4fe16364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss:\n",
      "0.8\n",
      "0.94\n",
      "Plane:\n",
      "0.78\n",
      "0.98\n",
      "Ortho:\n",
      "0.84\n",
      "0.89\n"
     ]
    }
   ],
   "source": [
    "X_discriminator_gauss = np.vstack((base_pc[::2], gauss_pc[::2]))\n",
    "X_discriminator_plane = np.vstack((base_pc[::2], plane_pc[::2]))\n",
    "X_discriminator_ortho = np.vstack((base_pc[::2], ortho_pc[::2]))\n",
    "y_discriminator = np.concatenate((np.zeros(ori_pc[::2].shape[0]), np.ones(ori_pc[::2].shape[0])))\n",
    "\n",
    "the_rf_gauss, train_acc_gauss = get_discriminator(X_discriminator_gauss, y_discriminator, n_estimators = 100)\n",
    "the_rf_plane, train_acc_plane = get_discriminator(X_discriminator_plane, y_discriminator, n_estimators = 100)\n",
    "the_rf_ortho, train_acc_ortho = get_discriminator(X_discriminator_ortho, y_discriminator, n_estimators = 100)\n",
    "\n",
    "print(\"Gauss:\")\n",
    "# print(train_acc_gauss)\n",
    "print(get_discriminator_performance(gauss_pc[1::2], np.ones(gauss_pc[1::2].shape[0]) , the_rf_gauss))\n",
    "print(get_discriminator_performance(base_pc, np.zeros(base_pc.shape[0]) , the_rf_gauss))\n",
    "\n",
    "print(\"Plane:\")\n",
    "# print(train_acc_plane)\n",
    "print(get_discriminator_performance(plane_pc[1::2], np.ones(plane_pc[1::2].shape[0]) , the_rf_plane))\n",
    "print(get_discriminator_performance(base_pc, np.zeros(base_pc.shape[0]) , the_rf_plane))\n",
    "\n",
    "print(\"Ortho:\")\n",
    "# print(train_acc_ortho)\n",
    "print(get_discriminator_performance(ortho_pc[1::2], np.ones(ortho_pc[1::2].shape[0]) , the_rf_ortho))\n",
    "print(get_discriminator_performance(base_pc, np.zeros(base_pc.shape[0]) , the_rf_ortho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d572a827-8a64-42a0-b3a1-e1d83711b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_LIME = 0.8\n",
    "\n",
    "lime_mask = np.random.uniform(0, 1, size=manifold_sampler.pivots.shape)\n",
    "lime_mask[lime_mask > p_LIME] = 1\n",
    "lime_mask[lime_mask <= p_LIME] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fee7634f-6458-4353-b63d-8b9a8310fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max = manifold_sampler.data_max.cpu().item()\n",
    "data_min = manifold_sampler.data_min.cpu().item()\n",
    "noise_uniform = np.random.uniform(data_min, data_max, size=manifold_sampler.pivots.shape)\n",
    "noise_mask = noise_uniform * lime_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a9e1dce-2aa5-49c3-9c32-cae4d8ddbe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_pc = base_pc.copy()\n",
    "lime_pc[noise_mask != 0] = noise_mask[noise_mask != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db12378f-a177-43ef-b165-a150a25da6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME:\n",
      "0.46\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "X_discriminator_lime = np.vstack((base_pc[::2], lime_pc[::2]))\n",
    "y_discriminator = np.concatenate((np.zeros(ori_pc[::2].shape[0]), np.ones(ori_pc[::2].shape[0])))\n",
    "\n",
    "# the_rf_lime, train_acc_lime = get_discriminator(X_discriminator_lime, y_discriminator, n_estimators = 100)\n",
    "\n",
    "print(\"LIME:\")\n",
    "# print(train_acc_gauss)\n",
    "print(get_discriminator_performance(lime_pc[1::2], np.ones(lime_pc[1::2].shape[0]) , the_rf_lime))\n",
    "print(get_discriminator_performance(base_pc, np.zeros(base_pc.shape[0]) , the_rf_gauss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e04de31e-188d-4c25-97ac-92568bd2b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_bg = ori_pc.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3f9fdd3-553d-4b5d-8c9a-b2037d60f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_bg = ori_pc.mean(axis = 0)\n",
    "SHAP_bg = np.tile(SHAP_bg,(ori_pc.shape[0],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887966ce-2995-4da9-bb05-9d5739e3536e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3e9da-ec7c-478c-93ba-4006e219513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7cd584b2-70ab-476b-8630-666ca188e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 0.1\n",
    "# print(\"Gauss:\")\n",
    "# # print(train_acc_gauss)\n",
    "# print(get_discriminator_performance(gauss_pc[1::2]-alpha*(gauss_pc[1::2]-base_pc[1::2]), np.ones(gauss_pc[1::2].shape[0]) , the_rf_gauss))\n",
    "\n",
    "# print(\"Plane:\")\n",
    "# # print(train_acc_plane)\n",
    "# print(get_discriminator_performance(plane_pc[1::2]-alpha*(plane_pc[1::2]-base_pc[1::2]), np.ones(plane_pc[1::2].shape[0]) , the_rf_plane))\n",
    "\n",
    "# print(\"Ortho:\")\n",
    "# # print(train_acc_ortho)\n",
    "# print(get_discriminator_performance(ortho_pc[1::2]-alpha*(ortho_pc[1::2]-base_pc[1::2]), np.ones(ortho_pc[1::2].shape[0]) , the_rf_ortho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a6233-feab-4121-8c5b-cb1dbd0d1893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def480db-5083-4d6c-a347-91b2eb4b3485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e08155-b69f-4d8e-94a2-1e4bc3f31e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9c17f-4d69-455c-b4d1-15aad34fbcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553de43d-b839-48de-a48a-fa9df650453e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b45b5e-5578-464d-8f52-b27751a3e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# manifold_sampler = Manifold_Tabular_Sampler(torch.tensor(xall), dim = DIM, labels = torch.tensor(y))\n",
    "# duration = time.time() - start_time\n",
    "# print(\"Initialize duration: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2026e6-83e9-43d0-82f5-1f2e1dc52a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7827645-8e70-48b0-8a11-6f93fd6463c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# manifold_sampler.train_pivots(number_of_pivots_per_label = 50,\n",
    "#                               number_of_local_perturbations = 50,\n",
    "#                               local_std = 0.01, \n",
    "#                               shuffle = False)\n",
    "# duration = time.time() - start_time\n",
    "# print(\"Train pivots duration: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb5724-d6ed-4e3d-8194-460e764af037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af7c4f80-03c8-4879-bb92-792513d2453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_gauss_old = manifold_sampler.gauss_perturbs.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23681a34-e33e-441f-9ddb-4ac7187b3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# ortho_perturbs = manifold_sampler.get_pivot_perturbations(radius = 1.0, \n",
    "#                                                          number_of_perturbations_per_pivot = 20,\n",
    "#                                                          test = True)\n",
    "# duration = time.time() - start_time\n",
    "# print(\"Perturbations generation duration: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aae7b49-9709-4437-93df-f95d0d7f613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_input = manifold_sampler.pivots.cpu().detach().numpy()\n",
    "# X_gauss = manifold_sampler.gauss_perturbs.cpu().detach().numpy()\n",
    "# X_plane = manifold_sampler.plane_perturbs.cpu().detach().numpy()\n",
    "# X_ortho = manifold_sampler.ortho_perturbs.cpu().detach().numpy()\n",
    "\n",
    "# print(X_input.shape)\n",
    "# print(X_gauss.shape)\n",
    "# print(X_plane.shape)\n",
    "# print(X_ortho.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4268c94-a066-4d41-a803-756a2e925429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_discriminator_gauss = np.vstack((X_gauss_old[::20], X_gauss[::20]))\n",
    "# X_discriminator_plane = np.vstack((X_gauss_old[::20], X_plane[::20]))\n",
    "# X_discriminator_ortho = np.vstack((X_gauss_old[::20], X_ortho[::20]))\n",
    "# y_discriminator = np.concatenate((np.zeros(X_input.shape[0]), np.ones(X_input.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec9b1fc-33d8-44fd-a9b2-13a2bada9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the_rf_gauss, train_acc_gauss = get_discriminator(X_discriminator_gauss, y_discriminator, n_estimators = 100)\n",
    "# the_rf_plane, train_acc_plane = get_discriminator(X_discriminator_plane, y_discriminator, n_estimators = 100)\n",
    "# the_rf_ortho, train_acc_ortho = get_discriminator(X_discriminator_ortho, y_discriminator, n_estimators = 100)\n",
    "\n",
    "# print(\"Gauss:\")\n",
    "# # print(train_acc_gauss)\n",
    "# print(get_discriminator_performance(X_gauss, np.ones(X_gauss.shape[0]) , the_rf_gauss))\n",
    "# # print(get_discriminator_performance(X_input, np.zeros(X_input.shape[0]) , the_rf_gauss))\n",
    "\n",
    "# print(\"Plane:\")\n",
    "# # print(train_acc_plane)\n",
    "# print(get_discriminator_performance(X_plane, np.ones(X_plane.shape[0]) , the_rf_plane))\n",
    "# # print(get_discriminator_performance(X_input, np.zeros(X_input.shape[0]) , the_rf_plane))\n",
    "\n",
    "# print(\"Ortho:\")\n",
    "# # print(train_acc_ortho)\n",
    "# print(get_discriminator_performance(X_ortho, np.ones(X_ortho.shape[0]) , the_rf_ortho))\n",
    "# # print(get_discriminator_performance(X_input, np.zeros(X_input.shape[0]) , the_rf_ortho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05029d88-aeec-4fe3-8a0e-8b676f294647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc9aab-7545-45ce-8d7f-7b7a3b60b2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd1365-c4f9-4cbd-84a8-f30d99b0c12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad13a4e-8c51-4b26-b1f4-87c52c0b38ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
