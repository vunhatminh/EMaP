{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422c453f-4185-4814-87ac-48dfbf63e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT:  fashion_mnist\n",
      "RADIUS:  1e-05\n",
      "DIM:  3\n",
      "PIVOTS:  10\n",
      "SHUFFLE:  False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "from fashion_model import FashionCNN \n",
    "from manifold_torch import Manifold_Image_Sampler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def similarity_kernel(v1,v2,kernel_width = 1):\n",
    "    l2_dist = np.linalg.norm(v1 - v2)\n",
    "    return np.exp(- (l2_dist**2) / (kernel_width**2))\n",
    "\n",
    "def normalize(v, r):\n",
    "    return v/np.sqrt(np.sum(v**2))*r\n",
    "\n",
    "def gen_mask(score, ones_ratio = 0.2):\n",
    "    no_rows, no_cols = score.shape\n",
    "    score_flat = np.reshape(score, no_rows*no_cols)\n",
    "    top_k = int(ones_ratio*no_rows*no_cols)\n",
    "    idx = np.argpartition(score_flat, -top_k)[-top_k:]\n",
    "    indices = idx[np.argsort((-score_flat)[idx])]\n",
    "    score_flat_dup = np.zeros_like(score_flat)\n",
    "    score_flat_dup[indices] = 1.0\n",
    "    score_dup = score_flat_dup.reshape(no_rows, no_cols)\n",
    "    return score_dup\n",
    "\n",
    "\n",
    "# prog_args = arg_parse()\n",
    "\n",
    "EXPERIMENT = 'fashion_mnist'\n",
    "RADIUS = 0.00001\n",
    "NUM_PERTURBATIONS = 10\n",
    "MULTIPLIER = 100\n",
    "DIM = 3\n",
    "PIVOTS = 10\n",
    "SHUFFLE = False\n",
    "BASE_RADIUS = 0.00001\n",
    "SIM_SIGMA = 4\n",
    "\n",
    "print(\"EXPERIMENT: \", EXPERIMENT)\n",
    "print(\"RADIUS: \", RADIUS)\n",
    "print(\"DIM: \", DIM)\n",
    "print(\"PIVOTS: \", PIVOTS)\n",
    "print(\"SHUFFLE: \", SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d4560b-5ce6-408e-af59-e59bfe84dc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fashion mnist\n",
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "if EXPERIMENT == 'fashion_mnist':\n",
    "    print(\"Loading fashion mnist\")\n",
    "    train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                    transforms.Compose([transforms.ToTensor()]))\n",
    "    test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                                   transforms.Compose([transforms.ToTensor()]))\n",
    "elif EXPERIMENT == 'mnist':\n",
    "    print(\"Loading mnist\")\n",
    "    train_set = torchvision.datasets.MNIST(\"./data\", download=True, transform=\n",
    "                                                    transforms.Compose([transforms.ToTensor()]))\n",
    "    test_set = torchvision.datasets.MNIST(\"./data\", download=True, train=False, transform=\n",
    "                                                   transforms.Compose([transforms.ToTensor()]))\n",
    "else:\n",
    "    print(\"Nothing to do.\")\n",
    "    \n",
    "print(\"Done loading\")\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=100)\n",
    "\n",
    "\n",
    "all_loader = torch.utils.data.DataLoader(train_set, batch_size=train_set.__len__())\n",
    "all_images, all_labels = next(iter(all_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818b66f3-2411-4598-b88b-d8cceb18c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize duration:  240.62030839920044\n"
     ]
    }
   ],
   "source": [
    "# Train the sampler\n",
    "all_loader = torch.utils.data.DataLoader(train_set, batch_size=train_set.__len__())\n",
    "all_images, all_labels = next(iter(all_loader))\n",
    "\n",
    "start_time = time.time()\n",
    "manifold_sampler = Manifold_Image_Sampler(all_images, dim = DIM, labels = all_labels)\n",
    "duration = time.time() - start_time\n",
    "print(\"Initialize duration: \", duration)\n",
    "\n",
    "# Get the pivots\n",
    "_ = manifold_sampler.get_pivots(manifold_sampler.labels, MULTIPLIER, shuffle = SHUFFLE, target_labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b222cee6-aee2-43d3-80be-e67da5002b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperplanes\n",
    "Gvs = []\n",
    "for group in torch.unique(manifold_sampler.labels):\n",
    "    manifold_G = manifold_sampler.get_G_from_samples(manifold_sampler.pivots[group.item()*MULTIPLIER:(group.item()+1)*MULTIPLIER])\n",
    "    Gu, Gd, Gv = np.linalg.svd(manifold_G, full_matrices=False)\n",
    "    Gvs.append(Gv)\n",
    "\n",
    "sample_to_Gv = {}\n",
    "group = -1\n",
    "for i in range(manifold_sampler.pivots.shape[0]):\n",
    "    if i % MULTIPLIER == 0:\n",
    "        group = group + 1\n",
    "    sample_to_Gv[i] = group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fada6f1-37e7-4edb-9cfd-fc567ebdf87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6191ca5f-b738-4b0c-89c9-fd37e0626841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get perturbations\n",
    "perturbations = []\n",
    "for _ in range(NUM_PERTURBATIONS):\n",
    "    for group in torch.unique(manifold_sampler.labels):\n",
    "        base_batch = manifold_sampler.pivots[group.item()*MULTIPLIER:(group.item()+1)*MULTIPLIER]\n",
    "        \n",
    "        # base\n",
    "        base_gauss_ = np.random.normal(0, 1, size=base_batch.shape)\n",
    "        r = np.random.uniform()*base_RADIUS\n",
    "        base_gauss_norm = normalize(base_gauss_, r)\n",
    "        base_pc = manifold_sampler.to_1d(base_batch + base_gauss_norm)\n",
    "    \n",
    "        # gauss\n",
    "        gauss_ = np.random.normal(0, 1, size=base_batch.shape)\n",
    "        gauss_noise = manifold_sampler.to_1d(gauss_)\n",
    "        plane_noise = np.zeros_like(gauss_noise)\n",
    "        for d in range(Gvs[group].shape[0]):\n",
    "            proj = np.dot(gauss_noise, Gvs[group][d])\n",
    "            for s in range(plane_noise.shape[0]):\n",
    "                plane_noise[s] = plane_noise[s] + proj[s]*Gvs[group][d]        \n",
    "        ortho_noise = gauss_noise - plane_noise\n",
    "    \n",
    "        # noise\n",
    "        r = np.random.uniform()*RADIUS\n",
    "        ortho_norm = normalize(ortho_noise, r)\n",
    "        ortho_pc = base_pc + ortho_norm\n",
    "    \n",
    "        perturbations.append(manifold_sampler.to_3d(ortho_pc))\n",
    "    \n",
    "perturbations = torch.cat(perturbations)    \n",
    "perturb_embeded = manifold_sampler.transform(perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada94c0-82b2-4c1d-87eb-baa8723ddc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89b492e-3e42-4ea5-91a3-648148046b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained/fashionCNN.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpt_file = 'pretrained/fashionCNN.pt'\n",
    "print(checkpt_file)\n",
    "\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(checkpt_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "028874a1-99b0-43e1-b420-c850629c0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_explain = 12\n",
    "image_to_explain = manifold_sampler.pivots[index_to_explain]\n",
    "\n",
    "perturb_outputs = model(perturbations.float().to(device))\n",
    "probs = nn.functional.softmax(perturb_outputs, dim = 1)\n",
    "\n",
    "original_output = model(image_to_explain.unsqueeze(0).to(device))\n",
    "original_prob = nn.functional.softmax(original_output, dim = 1)\n",
    "first_prediction, second_prediction = torch.topk(original_output, 2)[1][0]\n",
    "perturb_1st = probs[:,first_prediction.item()].cpu().detach().numpy()\n",
    "perturb_2nd = probs[:,second_prediction.item()].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31ca8393-d528-49f0-bfce-6f6fff639e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_embeded = manifold_sampler.transform(image_to_explain.unsqueeze(0))\n",
    "similarities = [similarity_kernel(perturb_embeded[i], base_embeded, kernel_width = SIM_SIGMA) for i in range(perturbations.shape[0])]\n",
    "repeat_shape = (perturbations.shape[0],) + tuple(np.ones(image_to_explain.ndim). astype(int))\n",
    "repeat_image_to_explain = image_to_explain.repeat(repeat_shape)\n",
    "true_perturb = perturbations - repeat_image_to_explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1b0780e-77df-4129-b417-c6f2bcf2b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_samples, channels, rows, cols = all_images.shape\n",
    "\n",
    "clf = linear_model.Ridge(alpha = 200)\n",
    "clf.fit(np.abs(true_perturb).reshape(true_perturb.shape[0], channels*rows*cols), perturb_1st, sample_weight=similarities)\n",
    "explanation_1st = -clf.coef_.reshape(rows, cols)\n",
    "clf.fit(np.abs(true_perturb).reshape(true_perturb.shape[0], channels*rows*cols), perturb_2nd, sample_weight=similarities)\n",
    "explanation_2nd = -clf.coef_.reshape(rows, cols)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(explanation_1st, cmap=plt.get_cmap('seismic'))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(explanation_2nd, cmap=plt.get_cmap('seismic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5660ba3b-5102-4efa-b767-23c63522a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mask(score, ones_ratio = 0.2):\n",
    "    no_rows, no_cols = score.shape\n",
    "    score_flat = np.reshape(score, no_rows*no_cols)\n",
    "    top_k = int(ones_ratio*no_rows*no_cols)\n",
    "    idx = np.argpartition(score_flat, -top_k)[-top_k:]\n",
    "    indices = idx[np.argsort((-score_flat)[idx])]\n",
    "    score_flat_dup = np.zeros_like(score_flat)\n",
    "    score_flat_dup[indices] = 1.0\n",
    "    score_dup = score_flat_dup.reshape(no_rows, no_cols)\n",
    "    return score_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baa97c08-4a4b-44f3-a197-c3e7bc2a9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_image = image_to_explain.clone().numpy()\n",
    "modified_mask = gen_mask(explanation_1st - explanation_2nd)\n",
    "modified_image[0][modified_mask==1] = 0.0\n",
    "modified_image = torch.tensor(modified_image)\n",
    "modified_output = model(modified_image.unsqueeze(0).to(device))\n",
    "modified_prob = nn.functional.softmax(modified_output, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6eaa6e93-b226-41b2-b1d1-56992cf6d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_log_odds = np.log(original_prob[0][first_prediction].cpu().detach().numpy()/original_prob[0][second_prediction].cpu().detach().numpy())\n",
    "modified_log_odds = np.log(modified_prob[0][first_prediction].cpu().detach().numpy()/modified_prob[0][second_prediction].cpu().detach().numpy())\n",
    "log_odds_score = original_log_odds - modified_log_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b91515e7-a4e8-401c-ac8d-3a03371b32f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2517347"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_odds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689f657-ea24-4350-9af5-0831e76aa43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
