{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73789b8-bd87-4f06-b805-f748c3ca5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT:  fashion_mnist\n",
      "MULTIPLIER:  100\n",
      "PERTURBATION_STD:  0.1\n",
      "DIM:  2\n",
      "PIVOTS:  10\n",
      "SHUFFLE:  True\n",
      "Loading fashion mnist\n",
      "Done loading\n",
      "Initialize duration:  73.38422083854675\n",
      "Train duration:  161.80371475219727\n",
      "1.0 100\n",
      "1.0 100\n",
      "1.0 100\n",
      "Create Testing environment\n",
      "Initialize duration:  57.322988510131836\n",
      "Train duration:  156.87672019004822\n",
      "0.995\n",
      "0.995\n",
      "0.955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "from fashion_model import FashionCNN \n",
    "from manifold_sampling import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# def arg_parse():\n",
    "#     parser = argparse.ArgumentParser(description=\"UMAP discriminator\")\n",
    "#     parser.add_argument(\n",
    "#             \"--exp\", dest=\"exp\", help=\"Experiments\"\n",
    "#         )\n",
    "#     parser.add_argument(\n",
    "#             \"--std\", dest=\"std\", type=float, help=\"Perturbation std\"\n",
    "#         )\n",
    "#     parser.add_argument(\n",
    "#         \"--multiplier\", dest=\"multiplier\", type=int, help=\"Number of times an image is perturbed\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--perturbations\", dest=\"num_perturbations\", type=int, help=\"Number of perturbations\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--dim\", dest=\"dim\", type=int, help=\"Number of low dim\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--pivots\", dest=\"pivots\", type=int, help=\"Number of pivots\"\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--shuffle\", dest=\"shuffle\", type=bool, help=\"Shuffle the pivots\"\n",
    "#     )\n",
    "    \n",
    "        \n",
    "#     parser.set_defaults(\n",
    "#         exp = 'fashion_mnist',\n",
    "#         std = 0.1,\n",
    "#         num_perturbations = 1,\n",
    "# #         runs = 10,\n",
    "#         multiplier = 100,\n",
    "#         dim = 2,\n",
    "#         pivots = 10,\n",
    "#         shuffle = True\n",
    "#     )\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# prog_args = arg_parse()\n",
    "\n",
    "\n",
    "EXPERIMENT = 'fashion_mnist'\n",
    "PERTURBATION_STD = 0.1\n",
    "NUM_PERTURBATIONS = 1\n",
    "MULTIPLIER = 100\n",
    "DIM = 2\n",
    "PIVOTS = 10\n",
    "SHUFFLE = True\n",
    "\n",
    "print(\"EXPERIMENT: \", EXPERIMENT)\n",
    "print(\"MULTIPLIER: \", MULTIPLIER)\n",
    "print(\"PERTURBATION_STD: \", PERTURBATION_STD)\n",
    "print(\"DIM: \", DIM)\n",
    "print(\"PIVOTS: \", PIVOTS)\n",
    "print(\"SHUFFLE: \", SHUFFLE)\n",
    "\n",
    "# EXPERIMENT = 'fashion_mnist'\n",
    "# EXPERIMENT = 'mnist'\n",
    "# EXPERIMENT = 'compass'\n",
    "# EXPERIMENT = 'german'\n",
    "\n",
    "if EXPERIMENT == 'fashion_mnist':\n",
    "    print(\"Loading fashion mnist\")\n",
    "    train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                    transforms.Compose([transforms.ToTensor()]))\n",
    "    test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                                   transforms.Compose([transforms.ToTensor()]))\n",
    "elif EXPERIMENT == 'mnist':\n",
    "    print(\"Loading mnist\")\n",
    "    train_set = torchvision.datasets.MNIST(\"./data\", download=True, transform=\n",
    "                                                    transforms.Compose([transforms.ToTensor()]))\n",
    "    test_set = torchvision.datasets.MNIST(\"./data\", download=True, train=False, transform=\n",
    "                                                   transforms.Compose([transforms.ToTensor()]))\n",
    "else:\n",
    "    print(\"Nothing to do.\")\n",
    "    \n",
    "print(\"Done loading\")\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=100)\n",
    "\n",
    "\n",
    "all_loader = torch.utils.data.DataLoader(train_set, batch_size=train_set.__len__())\n",
    "all_images, all_labels = next(iter(all_loader))\n",
    "\n",
    "start_time = time.time()\n",
    "manifold_sampler = Manifold_Image_Sampler(all_images, dim = DIM, labels = all_labels)\n",
    "duration = time.time() - start_time\n",
    "print(\"Initialize duration: \", duration)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "manifold_sampler.train_multiplier = MULTIPLIER\n",
    "manifold_sampler.std_train = PERTURBATION_STD\n",
    "manifold_sampler.train_pivot(no_pivots_per_label = PIVOTS, shuffle = SHUFFLE)\n",
    "duration = time.time() - start_time\n",
    "print(\"Train duration: \", duration)\n",
    "\n",
    "def get_discriminator(X,y,n_estimators = 100, test_ratio = 0.5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio)\n",
    "    the_rf = RandomForestClassifier(n_estimators=n_estimators).fit(X_train, y_train)\n",
    "    y_pred = the_rf.predict(X_test)\n",
    "    the_rf_result = (y_pred == y_test).sum()\n",
    "    return the_rf, the_rf_result/y_test.shape[0], X_train.shape[0]\n",
    "\n",
    "def get_discriminator_performance(X,y,rf):\n",
    "    y_pred = rf.predict(X)\n",
    "    the_rf_result = (y_pred == y).sum()\n",
    "    return the_rf_result/y.shape[0], y.shape[0]\n",
    "\n",
    "X_in = manifold_sampler.pivots.numpy()\n",
    "X_per = np.expand_dims(np.vstack([perturbs[0] for perturbs in manifold_sampler.perturbs]), axis = 1)\n",
    "X_plane = np.zeros_like(X_in)\n",
    "X_ortho = np.zeros_like(X_in)\n",
    "for i in range(X_plane.shape[0]):\n",
    "    X_plane[i] = manifold_sampler.pivots[i] + manifold_sampler.plane_noise[i][0]\n",
    "    X_ortho[i] = manifold_sampler.pivots[i] + manifold_sampler.ortho_noise[i][0]\n",
    "\n",
    "X_discriminator_per = np.vstack((X_in, X_per))\n",
    "X_discriminator_plane = np.vstack((X_in, X_plane))\n",
    "X_discriminator_ortho = np.vstack((X_in, X_ortho))\n",
    "y_discriminator = np.concatenate((np.zeros(X_in.shape[0]), np.ones(X_per.shape[0])))\n",
    "\n",
    "the_rf_per, test_acc_per, no_trains = get_discriminator(manifold_sampler.to_1d(X_discriminator_per),y_discriminator, n_estimators = 100, test_ratio = 0.5)\n",
    "print(test_acc, no_trains)\n",
    "the_rf_plane, test_acc_plane, no_trains = get_discriminator(manifold_sampler.to_1d(X_discriminator_plane),y_discriminator, n_estimators = 100, test_ratio = 0.5)\n",
    "print(test_acc, no_trains)\n",
    "the_rf_ortho, test_acc_ortho, no_trains = get_discriminator(manifold_sampler.to_1d(X_discriminator_ortho),y_discriminator, n_estimators = 100, test_ratio = 0.5)\n",
    "print(test_acc, no_trains)\n",
    "\n",
    "print(\"Create Testing environment\")\n",
    "\n",
    "start_time = time.time()\n",
    "explanation_sampler = Manifold_Image_Sampler(all_images, dim = DIM, labels = all_labels)\n",
    "duration = time.time() - start_time\n",
    "print(\"Initialize duration: \", duration)\n",
    "\n",
    "start_time = time.time()\n",
    "explanation_sampler.train_multiplier = MULTIPLIER\n",
    "explanation_sampler.std_train = PERTURBATION_STD\n",
    "explanation_sampler.train_pivot(no_pivots_per_label = PIVOTS, shuffle = True)\n",
    "duration = time.time() - start_time\n",
    "print(\"Train duration: \", duration)\n",
    "\n",
    "Z_in = explanation_sampler.pivots.numpy()\n",
    "acc_per = 0\n",
    "acc_plane = 0\n",
    "acc_ortho = 0\n",
    "var_per = 0 \n",
    "var_plane = 0\n",
    "var_ortho = 0\n",
    "for p in range(NUM_PERTURBATIONS):\n",
    "    Z_per = np.expand_dims(np.vstack([perturbs[p] for perturbs in explanation_sampler.perturbs]), axis = 1)\n",
    "    Z_plane = np.zeros_like(Z_in)\n",
    "    Z_ortho = np.zeros_like(Z_in)\n",
    "    for i in range(Z_plane.shape[0]):\n",
    "        Z_plane[i] = explanation_sampler.pivots[i] + explanation_sampler.plane_noise[i][p]\n",
    "        Z_ortho[i] = explanation_sampler.pivots[i] + explanation_sampler.ortho_noise[i][p]\n",
    "\n",
    "    Z_discriminator_per = np.vstack((Z_in, Z_per))\n",
    "    Z_discriminator_plane = np.vstack((Z_in, Z_plane))\n",
    "    Z_discriminator_ortho = np.vstack((Z_in, Z_plane))\n",
    "    y_discriminator = np.concatenate((np.zeros(Z_in.shape[0]), np.ones(Z_per.shape[0])))\n",
    "    \n",
    "    test_acc_per, no_test = get_discriminator_performance(explanation_sampler.to_1d(Z_discriminator_per), y_discriminator, the_rf_per)\n",
    "    test_acc_plane, no_test = get_discriminator_performance(explanation_sampler.to_1d(Z_discriminator_plane), y_discriminator, the_rf_plane)\n",
    "    test_acc_ortho, no_test = get_discriminator_performance(explanation_sampler.to_1d(Z_discriminator_ortho), y_discriminator, the_rf_ortho)\n",
    "    \n",
    "    acc_per = acc_per + test_acc_per\n",
    "    acc_plane = acc_plane + test_acc_plane\n",
    "    acc_ortho = acc_ortho + test_acc_ortho\n",
    "    var_per = var_per + np.var(Z_per-Z_in)\n",
    "    var_plane = var_plane + np.var(Z_plane-Z_in)\n",
    "    var_ortho = var_ortho + np.var(Z_ortho-Z_in)\n",
    "    \n",
    "acc_per = acc_per/NUM_PERTURBATIONS\n",
    "acc_plane = acc_plane/NUM_PERTURBATIONS\n",
    "acc_ortho = acc_ortho/NUM_PERTURBATIONS\n",
    "var_per = var_per/NUM_PERTURBATIONS\n",
    "var_plane = var_plane/NUM_PERTURBATIONS\n",
    "var_ortho = var_ortho/NUM_PERTURBATIONS\n",
    "\n",
    "df = pd.DataFrame({'per': [acc_per, test_acc_per, var_per],\n",
    "                   'plane': [acc_plane, test_acc_plane, var_plane],\n",
    "                   'ortho': [acc_ortho, test_acc_ortho, var_ortho]})\n",
    "\n",
    "discriminator_file = 'results/discriminator/' + EXPERIMENT + '_dim_' + str(DIM) + '_noise_' + str(PERTURBATION_STD) +'_.pickle'\n",
    "print(\"Save file to \", discriminator_file)\n",
    "with open(discriminator_file, 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "\n",
    "# result = []\n",
    "# # for test_ratio in list(np.arange(0.5,0.99,0.05)):\n",
    "# #     accs_umap = []\n",
    "# #     accs_base = []\n",
    "# #     for _ in range(NUM_RUNS):\n",
    "# #         acc_umap, _ = get_discriminator_performance(get_1d(all_x),all_y, test_ratio = test_ratio)\n",
    "# #         acc_base, n = get_discriminator_performance(get_1d(all_x_base),all_y, test_ratio = test_ratio)\n",
    "# #         accs_umap.append(acc_umap)\n",
    "# #         accs_base.append(acc_base)\n",
    "# #     mean_umap = np.mean(np.asarray(accs_umap))\n",
    "# #     std_umap = np.std(np.asarray(accs_umap))\n",
    "# #     mean_base = np.mean(np.asarray(accs_base))\n",
    "# #     std_base = np.std(np.asarray(accs_base))\n",
    "#     result.append((acc_per, std_per, ))\n",
    "    \n",
    "# df = pd.DataFrame.from_records(result, columns =['NoTrain', 'Base', 'std_base', 'Manifold', 'std_manifold'])\n",
    "\n",
    "# discriminator_file = 'results/discriminator/accuracy_on_' + EXPERIMENT + '_dim_' + str(DIM) + '_noise_' + str(PERTURBATION_STD) +'_.pickle'\n",
    "# print(\"Save file to \", discriminator_file)\n",
    "# with open(discriminator_file, 'wb') as output:\n",
    "#     pickle.dump(df, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1db7937-fee3-47f7-94e1-92897330c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'per': [acc_per, test_acc_per, var_per],\n",
    "                   'plane': [acc_plane, test_acc_plane, var_plane],\n",
    "                   'ortho': [acc_ortho, test_acc_ortho, var_ortho]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "252d8726-0383-4da5-9576-9a344b0c0776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per</th>\n",
       "      <th>plane</th>\n",
       "      <th>ortho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.006541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        per     plane     ortho\n",
       "0  0.995000  0.995000  0.955000\n",
       "1  1.000000  1.000000  1.000000\n",
       "2  0.000582  0.000033  0.006541"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_file = 'results/discriminator/' + EXPERIMENT + '_dim_' + str(DIM) + '_noise_' + str(PERTURBATION_STD) +'_.pickle'\n",
    "print(\"Save file to \", discriminator_file)\n",
    "with open(discriminator_file, 'wb') as output:\n",
    "    pickle.dump(df, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4eb2b9d9-d725-4a9c-9ec9-7845d6307287",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file = 'results/discriminator/' + 'mnist' + '_dim_' + str(2) + '_std_' + str(0.1) +'_.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70066b55-0f1c-484d-a2f6-206dc107598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(load_file, 'rb') as file:\n",
    "    load_data = pickle.load(file)\n",
    "\n",
    "df = load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef61fc5d-efac-4b4a-9126-094ea7648494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>per</th>\n",
       "      <th>plane</th>\n",
       "      <th>ortho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.991600</td>\n",
       "      <td>0.745950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        per     plane     ortho\n",
       "0  0.999950  0.991600  0.745950\n",
       "1  1.000000  0.995000  0.710000\n",
       "2  0.000639  0.000039  0.004385"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb5f81-04fe-45d5-9393-0e6577dcad6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
